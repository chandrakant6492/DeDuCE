{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87655f8-c745-4591-9d00-154f0a52c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandra/.local/lib/python3.10/site-packages/xarray/backends/cfgrib_.py:29: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1162aacf-79ed-4737-9576-803e92e887a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Calculate area\n",
    "def areaquad(lat_max, lat_min, lon_max, lon_min, csize, shape, datum = 'wgs84', unit='km'):\n",
    "    global r2\n",
    "    '''Creates a GCS raster with cell size csize where the cell value is the\n",
    "    area of the cell in the unit specified\n",
    "    Usage: >>> test = areaquad(lat_max, lat_min, lon_max, lon_min, 'wgs84', 0.25, 'km')'''\n",
    "\n",
    "    # Common ellipsoid library major, minor axis.\n",
    "    # Can add more ellipsoids to dictionary library as you go\n",
    "    datum_lib = {'wgs84': [6378137.0, 6356752.3],\n",
    "                 'nad83': [6378137.0, 6356752.3],\n",
    "                 'nad27': [6378206.4, 6356583.8],\n",
    "                 'sad69': [6378160.0, 6356774.72],\n",
    "                 'sirgas2000': [6378137.0, 6356752.3]}\n",
    "    a, b = datum_lib.get(datum) # Get ellipsoid parameters\n",
    "    e2 = (a**2 - b**2)/(a**2)\n",
    "    e = math.sqrt(e2) # Eccentricity\n",
    "    r_2 = math.sqrt((a**2/2) + (b**2/2) * (math.atanh(e)/e)) # Authalic radius\n",
    "\n",
    "    # Output array dimension\n",
    "    nrow = shape[0]\n",
    "    ncol = shape[1]\n",
    "\n",
    "    # Create arrays of cells of equal size in dd, convert to radians\n",
    "    lats1 = np.linspace(lat_max, lat_min + csize, num=nrow)\n",
    "    lats2 = lats1 - csize\n",
    "    latin1 = np.radians(lats1)\n",
    "    latin2 = np.radians(lats2)\n",
    "\n",
    "    # Convert latitudes to authalic latitudes. See Snyder (1987, p.16 eq. 3-18)\n",
    "    # (want to find beta, not theta, that's why you subtract the series)\n",
    "    # Factor expansion series\n",
    "    fact1 = e**2 / 3 + 31 * e**4 / 180 + 517 * e**6 / 5040 # Expansion series 1\n",
    "    fact2 = 23 * e**4 / 360 + 251 * e**6 / 3780 # Expansion series 2\n",
    "    fact3 = 761 * e**6 / 45360 # Expansion series 3\n",
    "    latout1 = latin1 - fact1 * np.sin(2 * latin1) + fact2 * np.sin(4 * latin1) + fact3 * np.sin(6 * latin1)\n",
    "    latout2 = latin2 - fact1 * np.sin(2 * latin2) + fact2 * np.sin(4 * latin2) + fact3 * np.sin(6 * latin2)\n",
    "\n",
    "    # report value in preferred unit\n",
    "    if unit == 'm':  # either in meters or km (default)\n",
    "        r2 = r_2  # radius in meters\n",
    "    else:\n",
    "        r2 = r_2 / 1000.0  # in km\n",
    "    # calculate area of square on spherical surface\n",
    "    cst = (np.pi / 180) * (r2 ** 2)  # just a constant; see Snyder 1987.\n",
    "    area = cst * (np.absolute(np.sin(latout1) - np.sin(latout2))) * np.absolute(csize)\n",
    "    # replicate column over Earth's extent\n",
    "    grid = np.tile(area, (ncol, 1)).T  # replicate lat and transpose because\n",
    "    # area is stored as a row array, not column\n",
    "    return grid * 100  # Converted to ha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4073c6-decb-4769-86d5-272205c72c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "shapefile_path = '/home/chandra/backup/Chalmers/Other_datasets/GADM/GADM_dissolved_ADM0.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a482193-db3c-43a6-9bcf-82a1cd48aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature collection (i.e., boundary shapefile in csv format) needed to simulate aggregation\n",
    "# Note: that this csv file will just contain countries names, but the actual boundary (be it first or second level admin boundary) that is being simulated should be uploaded in GEE\n",
    "GADM_countries = pd.read_csv(\"/home/chandra/backup/Chalmers/GADM_Boundaries.csv\")\n",
    "\n",
    "# Groupby and count the attributes/shapes in the dataframe, just to get a sense of number of distinct sub-boundaries within a country\n",
    "counts = GADM_countries.groupby('COUNTRY').size().reset_index(name='count')\n",
    "\n",
    "# Resulting dataframe with distinct Countries and unique sub-boundaries within them\n",
    "Countries = pd.DataFrame(counts[['COUNTRY', 'count']]).sort_values(by='count')\n",
    "\n",
    "# Check total countries that will be simulated\n",
    "Countries = Countries.COUNTRY.values\n",
    "Countries.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd09e852-7297-4eb9-93a6-35a368bca2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gross_change(Country, year):\n",
    "    \n",
    "    global clipped, pixel_area, result_crop, result_grass\n",
    "    \n",
    "    # Filter the shapefile to extract the geometry\n",
    "    shape = gdf[gdf['COUNTRY'] == Country]\n",
    "    \n",
    "    # Get the bounding box of the Sweden GeoDataFrame\n",
    "    bounds = shape.total_bounds\n",
    "    # Extract lat_max, lat_min, lon_max, lon_min\n",
    "    lon_min, lat_min, lon_max, lat_max = bounds\n",
    "    \"\"\"\n",
    "    # Print the extracted values\n",
    "    print('lat_max:', lat_max)\n",
    "    print('lat_min:', lat_min)\n",
    "    print('lon_max:', lon_max)\n",
    "    print('lon_min:', lon_min)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the TIFF file\n",
    "    tiff_path = '/home/chandra/backup/Chalmers/Other_datasets/C3S-LC-L4-LCCS-Map-300m-P1Y-'+str(year-1)+'-v2.1.1.tif'\n",
    "    with rasterio.open(tiff_path) as src:\n",
    "        # Clip the TIFF using the shapefile's geometry\n",
    "        clipped, transform = mask(src, shapes=shape.geometry, crop=True)\n",
    "        \n",
    "        # Update the metadata\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'height': clipped.shape[1],\n",
    "            'width': clipped.shape[2],\n",
    "            'transform': transform\n",
    "        })\n",
    "    csize = transform[0]\n",
    "    shape_array = clipped[0].shape\n",
    "    #print('Cell size:', csize)\n",
    "    #print('shape:', shape_array)\n",
    "    \n",
    "    # Load the TIFF file\n",
    "    tiff_path = '/home/chandra/backup/Chalmers/Other_datasets/C3S-LC-L4-LCCS-Map-300m-P1Y-'+str(year)+'-v2.1.1.tif'\n",
    "    with rasterio.open(tiff_path) as src:\n",
    "        # Clip the TIFF using the shapefile's geometry\n",
    "        clipped1, transform = mask(src, shapes=shape.geometry, crop=True)\n",
    "\n",
    "        # Update the metadata\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'height': clipped1.shape[1],\n",
    "            'width': clipped1.shape[2],\n",
    "            'transform': transform\n",
    "        })\n",
    "    \n",
    "    pixel_area = areaquad(lat_max, lat_min, lon_max, lon_min, csize, shape_array) # Pixel area in 'ha'\n",
    "    # Load the confidence matrix as a DataFrame\n",
    "    Conversion_matrix = pd.read_excel('/home/chandra/backup/Chalmers/Other_datasets/Conversion factor Li et al 2017.xlsx', 'Aggregated CF', index_col=0).fillna(0)\n",
    "\n",
    "    # Get the pixel values as arrays\n",
    "    PFT_y_values = clipped1[0] \n",
    "    PFT_y_1_values = clipped[0] \n",
    "\n",
    "    # Initialize an empty array for the results\n",
    "    result_crop = np.zeros_like(PFT_y_values, dtype=float)\n",
    "    result_grass = np.zeros_like(PFT_y_values, dtype=float)\n",
    "\n",
    "    # Iterate over each pixel\n",
    "    for i in range(len(PFT_y_values)):\n",
    "        # Get the pixel values for A and B\n",
    "        a_pixel = PFT_y_values[i]\n",
    "        b_pixel = PFT_y_1_values[i]\n",
    "        area = pixel_area[i]\n",
    "        \n",
    "        if Country == 'Sudan':\n",
    "            a_pixel = np.where(a_pixel == 151, 150, a_pixel) # Something weird happing with two pixel getting a value of 151 (not in their classification)\n",
    "            b_pixel = np.where(b_pixel == 151, 150, b_pixel)\n",
    "        # Get the conversion factor from the confidence matrix\n",
    "        crop_conversion_factor_a_pixel = Conversion_matrix.loc[a_pixel, 'Crop']\n",
    "        crop_conversion_factor_b_pixel = Conversion_matrix.loc[b_pixel, 'Crop']\n",
    "\n",
    "        grass_conversion_factor_a_pixel = Conversion_matrix.loc[a_pixel, 'Grass']\n",
    "        grass_conversion_factor_b_pixel = Conversion_matrix.loc[b_pixel, 'Grass']\n",
    "\n",
    "        # Calculate the result for the current pixel\n",
    "        result_crop[i] = (crop_conversion_factor_a_pixel.values - crop_conversion_factor_b_pixel.values)*area/100 # Converting pecentage to ratio; Area in 'ha'\n",
    "        result_grass[i] = (grass_conversion_factor_a_pixel.values - grass_conversion_factor_b_pixel.values)*area/100\n",
    "    \n",
    "    result_crop_loss = np.sum(result_crop[result_crop < 0])\n",
    "    result_grass_loss = np.sum(result_grass[result_grass < 0])\n",
    "    return result_crop_loss, result_grass_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e1285-d7db-4b5c-a1e7-10bd7d667d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 239/253 [3:08:16<1:12:19, 309.96s/it]"
     ]
    }
   ],
   "source": [
    "Li_et_al = pd.DataFrame()\n",
    "Li_et_al['Country'] = Countries\n",
    "\n",
    "for year in range(2001, 2021):\n",
    "    print(year)\n",
    "    Croploss_final = []\n",
    "    Grassloss_final = []\n",
    "\n",
    "    for Country in tqdm(Countries):\n",
    "        Croploss, Grassloss = Gross_change(Country, year)\n",
    "        Croploss_final.append(Croploss)\n",
    "        Grassloss_final.append(Grassloss)\n",
    "\n",
    "    Li_et_al['Croploss_'+str(year)] = Croploss_final\n",
    "    Li_et_al['Grassloss_'+str(year)] = Grassloss_final\n",
    "\n",
    "Li_et_al.loc[:, Li_et_al. columns != 'Country'] = Li_et_al.loc[:, Li_et_al. columns != 'Country']/(10**8) # Converting to 'Million km2'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9607f3a-7f8e-4970-b7a8-97a641efa154",
   "metadata": {},
   "source": [
    "Li_et_al.to_csv('/home/chandra/backup/Chalmers/Other_datasets/Li_et_al_2017_Gross_cropland_grassland_changes_2019-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873b9c6-f3e4-4065-ba77-d1b5e426d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an Excel writer object\n",
    "excel_writer = pd.ExcelWriter('/home/chandra/backup/Chalmers/Other_datasets/Li_et_al_2017_Gross_cropland_grassland_changes_2001-2020.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write the first data frame to a sheet named 'crop_loss'\n",
    "(Li_et_al[['Country'] + [f'Croploss_{year}' for year in range(2001, 2021)]]).to_excel(excel_writer, sheet_name='crop_loss', index=False)\n",
    "\n",
    "# Write the second data frame to a sheet named 'grass_loss'\n",
    "(Li_et_al[['Country'] + [f'Grassloss_{year}' for year in range(2001, 2021)]]).to_excel(excel_writer, sheet_name='grass_loss', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "excel_writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b79f3b-53cb-43e8-b2d9-dc47da191d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
